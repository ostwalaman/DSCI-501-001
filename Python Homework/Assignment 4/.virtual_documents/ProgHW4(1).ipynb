











from collections import Counter, defaultdict
import math,re

def tokenize(message):
    """
    extracts the set of unique words from the given text message
    INPUT:
        message: a piece of text
    OUTPUT:
        a set of unique words
    """
    message = message.lower()                       # convert to lowercase
    all_words = re.findall("[a-z0-9']+", message)   # extract the words
    return set(all_words)                           # remove duplicates


def count_words(training_set):
    """
    creates a dictionary containing the mappings from unique words to the frequencies of the words in 
    spam and non-spam messages in the training set
    INPUT:
        training_set: training set consists of pairs (message, is_spam)
    OUTPUT:
        a map from unique words to their frequencies in spam and non-spam messages
    """
    counts = defaultdict(lambda: [0, 0])
    for message, is_spam in training_set:
        for word in tokenize(message):
            counts[word][0 if is_spam else 1] += 1
    return counts


def word_probabilities(counts, total_spams, total_non_spams, k=0.5):
    """
    turns the word_counts into a list of triplets w, p(w | spam) and p(w | ~spam)
    INPUT:
        counts: a maps from unique words to their frequencies in spam and non-spam messages
        total_spams: the total number of spam messages
        total_non_spams: the total number of non-spam messages
        k=0.5: the smoothing parameter, default 0.5
    OUTPUT:
        a list of triples (w, p(w|spam), p(w|non-spam))
    """
    return [(w,
             (spam + k) / (total_spams + 2 * k),
             (non_spam + k) / (total_non_spams + 2 * k))
             for w, (spam, non_spam) in counts.items()]


def spam_probability(word_probs, message, total_spams, total_non_spams, k = 0.5):
    """
    computes the probablity of spam for the given message
    INPUT:
        word_probs: a list of triple (w, p(w|spam), p(w|non-spam))
        message: a message under classification
    OUTPUT:
        the probability of being spam for the message
    HINTS:
        First, get a set of unique words in the mesage.
        Second, sum up all the log probabilities of the unique words in the message.
        Third, get probabilities by taking exponentials of the probabilites (for spam and non-spam).
        Finally, return the ratio of probability of spam over the sum of the probabiliy of spam and the 
        probability of not spam.
    """
    ############YOUR CODE HERE##################
   
    
    return prob_spam / (prob_spam + prob_ham)

    ############################################


def naiveBayes_classify(word_probs, message, total_spams, total_non_spams, k):
    """
    classifies the message as spam or ham
    INPUT:
        word_probs: a list of triples (w, p(w|spam), p(w|non-spam))
        message: the message under classifiation
    OUTPUT:
        'spam' or 'ham' indicating the classification of the message.
    """
    





import pandas as pd
import numpy as np
spam = pd.read_csv("spam.csv", encoding = 'ISO-8859-1')


spam.head()


spam.shape


spam['is_spam'] = spam['label'].map({'spam':1, 'ham':0})


spam.head()


# Splitting the dataset into the Training set and Test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(spam['text'], spam['is_spam'], test_size = 0.2, random_state = 0)


y_test = list(y_test.map({0:'ham',1:'spam'}))


training_set = zip(X_train,y_train)


counts = count_words(training_set)


counts


total_spams = y_train.sum()
total_spams


total_non_spams = y_train.shape[0] - total_spams
total_non_spams


word_probs = word_probabilities(counts, total_spams, total_non_spams, k=0.5)


#just check if this works for any given text in the dataset.
naiveBayes_classify(word_probs, spam['text'][2], total_spams, total_non_spams, 0.5)


X_train.iloc[0]


X_test.iloc[0]


y_pred = []
for i in range(X_test.shape[0]):
    y_pred.append(naiveBayes_classify(word_probs, X_test.iloc[i], total_spams, total_non_spams, 0.5))


from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))


from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score

print("Accuracy score: ", accuracy_score(y_test, y_pred))
print("Recall score: ", recall_score(y_test, y_pred, average = 'weighted'))
print("Precision score: ", precision_score(y_test, y_pred, average = 'weighted'))
print("F1 score: ", f1_score(y_test, y_pred, average = 'weighted'))
